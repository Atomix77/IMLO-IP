{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Atomix77/IMLO-IP/blob/main/IMLO_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QNZzt3qRxj22"
      },
      "source": [
        "# Load Data\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "rPqbMcduQaTJ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor, Lambda\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "\n",
        "mean=[0.485, 0.456, 0.406]\n",
        "std=[0.229, 0.224, 0.225]\n",
        "\n",
        "trainingTransform = transforms.Compose([\n",
        "      transforms.Resize((224, 224)),\n",
        "      transforms.ToTensor(),\n",
        "      transforms.RandomHorizontalFlip(),\n",
        "      transforms.RandomRotation(20),\n",
        "      transforms.Normalize(torch.Tensor(mean), torch.Tensor(std)),])\n",
        "\n",
        "testTransform = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(torch.Tensor(mean), torch.Tensor(std)),])\n",
        "\n",
        "trainingData = datasets.Flowers102(\n",
        "    root = \"./datasets\",\n",
        "    split = \"train\",\n",
        "    transform = trainingTransform,\n",
        "    # target_transform = Lambda(lambda y: torch.zeros(1000, dtype=torch.float).scatter_(0, torch.tensor(y), value=1)),\n",
        "    download = True)\n",
        "\n",
        "validationData = datasets.Flowers102(\n",
        "    root = \"./datasets\",\n",
        "    split = \"val\",\n",
        "    transform = testTransform,\n",
        "    # target_transform = Lambda(lambda y: torch.zeros(1000, dtype=torch.float).scatter_(0, torch.tensor(y), value=1)),\n",
        "    download = True)\n",
        "\n",
        "testData = datasets.Flowers102(\n",
        "    root = \"./datasets\",\n",
        "    split = \"test\",\n",
        "    transform = testTransform,\n",
        "    # target_transform = Lambda(lambda y: torch.zeros(1000, dtype=torch.float).scatter_(0, torch.tensor(y), value=1)),\n",
        "    download = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WJvmzTaHdnlp"
      },
      "source": [
        "# Dataloaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "lJxe_JHFdp5v"
      },
      "outputs": [],
      "source": [
        "batchSize = 64\n",
        "\n",
        "trainingDataloader = DataLoader(trainingData, batchSize, shuffle = True, num_workers = 6)\n",
        "validationDataloader = DataLoader(validationData, batchSize, shuffle = False, num_workers = 6)\n",
        "testDataloader = DataLoader(testData, batchSize, shuffle = False, num_workers = 6)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "10tVZxhv6guP"
      },
      "source": [
        "# Get device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tOZbLdGEsfV2",
        "outputId": "f2f6f56c-12bb-47eb-e8bc-3e8c298ef4bc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using cuda device\n"
          ]
        }
      ],
      "source": [
        "device = (\n",
        "    \"cuda\"\n",
        "    if torch.cuda.is_available()\n",
        "    else \"mps\"\n",
        "    if torch.backends.mps.is_available()\n",
        "    else \"cpu\"\n",
        ")\n",
        "print(f\"Using {device} device\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vn49i-601HQm"
      },
      "source": [
        "# Create Aritecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "DEtkf2DSxjNd"
      },
      "outputs": [],
      "source": [
        "class NeuralNetwork(nn.Module):\n",
        "  def __init__(self, classAmount):\n",
        "    super(NeuralNetwork, self).__init__()\n",
        "    self.convStack =  nn.Sequential(\n",
        "      nn.Conv2d(in_channels = 3, out_channels = 32, kernel_size = 3, padding = 1),\n",
        "      nn.BatchNorm2d(32),\n",
        "      nn.ReLU(),\n",
        "      nn.MaxPool2d(kernel_size = 2, stride = 2),\n",
        "      nn.Conv2d(in_channels = 32, out_channels = 64, kernel_size = 3, padding = 1),\n",
        "      nn.BatchNorm2d(64),\n",
        "      nn.ReLU(),\n",
        "      nn.MaxPool2d(kernel_size = 2, stride = 2),\n",
        "      nn.Conv2d(in_channels = 64, out_channels = 128, kernel_size = 3, padding = 1),\n",
        "      nn.BatchNorm2d(128),\n",
        "      nn.ReLU(),\n",
        "      nn.MaxPool2d(kernel_size = 2, stride = 2),\n",
        "      nn.Conv2d(in_channels = 128, out_channels = 256, kernel_size = 3, padding = 1),\n",
        "      nn.BatchNorm2d(256),\n",
        "      nn.ReLU(),\n",
        "      nn.MaxPool2d(kernel_size = 2, stride = 2),\n",
        "      nn.Conv2d(in_channels = 256, out_channels = 512, kernel_size = 3, padding = 1),\n",
        "      nn.BatchNorm2d(512),\n",
        "      nn.ReLU(),\n",
        "      nn.MaxPool2d(kernel_size = 2, stride = 2),\n",
        "      nn.Dropout(0.5)\n",
        "      )\n",
        "    self.classifier = nn.Sequential(\n",
        "      nn.Linear(32 * 28 * 28, 1024),\n",
        "      nn.ReLU(),\n",
        "      nn.Dropout(0.5),\n",
        "      nn.Linear(1024, classAmount)\n",
        "      )\n",
        "    \n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.convStack(x)\n",
        "    x = torch.flatten(x, 1)\n",
        "    x = self.classifier(x)\n",
        "    return x\n",
        "  \n",
        "  \n",
        "model = NeuralNetwork(102).to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "def testModel(dataloader, model, lossFunction):\n",
        "  model.eval()\n",
        "  total = 0\n",
        "  correct = 0\n",
        "  testLoss = 0\n",
        "  \n",
        "  with torch.no_grad():\n",
        "    for X, y in dataloader:\n",
        "      X, y = X.to(device), y.to(device)\n",
        "      pred = model(X)\n",
        "      total += y.size(0)\n",
        "      testLoss += lossFunction(pred, y).item()\n",
        "      correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "  \n",
        "  testLoss = testLoss/total\n",
        "  correct = (correct/total) * 100\n",
        "  print(f\"Testing: Accuracy: {(correct):>0.1f}%, Avg loss: {testLoss:>8f} \\n\")\n",
        "  return testLoss, correct"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u1w_yEPkDiOo"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "s1wDws8xJOfQ"
      },
      "outputs": [],
      "source": [
        "earlyStopCount = 5\n",
        "def trainingModel(dataloader, model, lossFunction, optimizer, epochs):\n",
        "  bestValLoss = float('inf')\n",
        "  bestValAccuracy = 0\n",
        "  waitCounter = 0\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "    model.train()\n",
        "    print(f'Epoch{epoch+1}:')\n",
        "    currentLoss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    testLoss = 0\n",
        "    \n",
        "    for X, y in dataloader:\n",
        "      X, y = X.to(device), y.to(device)\n",
        "      optimizer.zero_grad()\n",
        "      \n",
        "      pred = model(X)\n",
        "      loss = lossFunction(pred, y)\n",
        "\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      currentLoss += loss.item()\n",
        "\n",
        "      total += y.size(0)\n",
        "      testLoss += lossFunction(pred, y).item()\n",
        "      correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "    \n",
        "    testLoss = testLoss/total\n",
        "    correct = correct/total\n",
        "    print(f'Training: Accuracy {(100*correct):>0.1f}%, Loss: {currentLoss / len(dataloader):.5f}, Test Losss: {testLoss:.5f}')\n",
        "    \n",
        "    valLoss, valAccuracy = testModel(validationDataloader, model, lossFunction)\n",
        "    if (valAccuracy < bestValAccuracy):\n",
        "      waitCounter += 1\n",
        "    else:\n",
        "      bestValLoss = valLoss\n",
        "      bestValAccuracy = valAccuracy\n",
        "      waitCounter = 0\n",
        "\n",
        "    # if waitCounter > earlyStopCount:\n",
        "    #   print(f'Validation has not improved for {earlyStopCount} epochs.')\n",
        "    #   break\n",
        "  print(f'Best Accuracy: {bestValAccuracy}. Best Loss: {bestValLoss}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 495
        },
        "id": "-8n5NAvIJUuO",
        "outputId": "50d3d6ee-ddaa-4bba-f3e4-d5f5448cb12b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch1:\n",
            "Training: Accuracy 1.8%, Loss: 4.87664, Test Losss: 0.07650\n",
            "Testing: Accuracy: 1.6%, Avg loss: 0.071814 \n",
            "\n",
            "Epoch2:\n",
            "Training: Accuracy 4.4%, Loss: 4.34351, Test Losss: 0.06813\n",
            "Testing: Accuracy: 8.3%, Avg loss: 0.065630 \n",
            "\n",
            "Epoch3:\n",
            "Training: Accuracy 8.1%, Loss: 4.05523, Test Losss: 0.06361\n",
            "Testing: Accuracy: 13.9%, Avg loss: 0.059956 \n",
            "\n",
            "Epoch4:\n",
            "Training: Accuracy 11.6%, Loss: 3.80884, Test Losss: 0.05975\n",
            "Testing: Accuracy: 18.6%, Avg loss: 0.056605 \n",
            "\n",
            "Epoch5:\n",
            "Training: Accuracy 15.9%, Loss: 3.51966, Test Losss: 0.05521\n",
            "Testing: Accuracy: 21.1%, Avg loss: 0.053515 \n",
            "\n",
            "Epoch6:\n",
            "Training: Accuracy 21.8%, Loss: 3.32939, Test Losss: 0.05223\n",
            "Testing: Accuracy: 25.6%, Avg loss: 0.051287 \n",
            "\n",
            "Epoch7:\n",
            "Training: Accuracy 22.4%, Loss: 3.14978, Test Losss: 0.04941\n",
            "Testing: Accuracy: 26.6%, Avg loss: 0.048756 \n",
            "\n",
            "Epoch8:\n",
            "Training: Accuracy 25.6%, Loss: 3.02928, Test Losss: 0.04752\n",
            "Testing: Accuracy: 29.6%, Avg loss: 0.047305 \n",
            "\n",
            "Epoch9:\n",
            "Training: Accuracy 29.3%, Loss: 2.81252, Test Losss: 0.04412\n",
            "Testing: Accuracy: 30.9%, Avg loss: 0.046506 \n",
            "\n",
            "Epoch10:\n",
            "Training: Accuracy 34.4%, Loss: 2.68593, Test Losss: 0.04213\n",
            "Testing: Accuracy: 29.6%, Avg loss: 0.045339 \n",
            "\n",
            "Epoch11:\n",
            "Training: Accuracy 37.4%, Loss: 2.56767, Test Losss: 0.04028\n",
            "Testing: Accuracy: 32.2%, Avg loss: 0.043693 \n",
            "\n",
            "Epoch12:\n",
            "Training: Accuracy 40.8%, Loss: 2.40883, Test Losss: 0.03779\n",
            "Testing: Accuracy: 35.0%, Avg loss: 0.041846 \n",
            "\n",
            "Epoch13:\n",
            "Training: Accuracy 44.1%, Loss: 2.25021, Test Losss: 0.03530\n",
            "Testing: Accuracy: 36.1%, Avg loss: 0.041290 \n",
            "\n",
            "Epoch14:\n",
            "Training: Accuracy 43.6%, Loss: 2.17627, Test Losss: 0.03414\n",
            "Testing: Accuracy: 37.1%, Avg loss: 0.040317 \n",
            "\n",
            "Epoch15:\n",
            "Training: Accuracy 48.9%, Loss: 2.00194, Test Losss: 0.03140\n",
            "Testing: Accuracy: 37.3%, Avg loss: 0.040584 \n",
            "\n",
            "Epoch16:\n",
            "Training: Accuracy 49.3%, Loss: 1.89675, Test Losss: 0.02975\n",
            "Testing: Accuracy: 37.4%, Avg loss: 0.039056 \n",
            "\n",
            "Epoch17:\n",
            "Training: Accuracy 53.3%, Loss: 1.80744, Test Losss: 0.02835\n",
            "Testing: Accuracy: 39.6%, Avg loss: 0.038310 \n",
            "\n",
            "Epoch18:\n",
            "Training: Accuracy 55.4%, Loss: 1.67718, Test Losss: 0.02631\n",
            "Testing: Accuracy: 41.0%, Avg loss: 0.037353 \n",
            "\n",
            "Epoch19:\n",
            "Training: Accuracy 55.8%, Loss: 1.66653, Test Losss: 0.02614\n",
            "Testing: Accuracy: 41.5%, Avg loss: 0.036611 \n",
            "\n",
            "Epoch20:\n",
            "Training: Accuracy 58.6%, Loss: 1.53655, Test Losss: 0.02410\n",
            "Testing: Accuracy: 42.8%, Avg loss: 0.036433 \n",
            "\n",
            "Epoch21:\n",
            "Training: Accuracy 63.3%, Loss: 1.43310, Test Losss: 0.02248\n",
            "Testing: Accuracy: 41.9%, Avg loss: 0.036347 \n",
            "\n",
            "Epoch22:\n",
            "Training: Accuracy 62.9%, Loss: 1.35416, Test Losss: 0.02124\n",
            "Testing: Accuracy: 43.1%, Avg loss: 0.035540 \n",
            "\n",
            "Epoch23:\n",
            "Training: Accuracy 65.9%, Loss: 1.27930, Test Losss: 0.02007\n",
            "Testing: Accuracy: 42.5%, Avg loss: 0.035450 \n",
            "\n",
            "Epoch24:\n",
            "Training: Accuracy 66.9%, Loss: 1.22732, Test Losss: 0.01925\n",
            "Testing: Accuracy: 40.7%, Avg loss: 0.036340 \n",
            "\n",
            "Epoch25:\n",
            "Training: Accuracy 68.7%, Loss: 1.15006, Test Losss: 0.01804\n",
            "Testing: Accuracy: 42.7%, Avg loss: 0.035290 \n",
            "\n",
            "Epoch26:\n",
            "Training: Accuracy 72.9%, Loss: 1.06568, Test Losss: 0.01672\n",
            "Testing: Accuracy: 44.7%, Avg loss: 0.033913 \n",
            "\n",
            "Epoch27:\n",
            "Training: Accuracy 72.5%, Loss: 1.02355, Test Losss: 0.01606\n",
            "Testing: Accuracy: 46.3%, Avg loss: 0.034099 \n",
            "\n",
            "Epoch28:\n",
            "Training: Accuracy 75.3%, Loss: 0.97326, Test Losss: 0.01527\n",
            "Testing: Accuracy: 46.0%, Avg loss: 0.033661 \n",
            "\n",
            "Epoch29:\n",
            "Training: Accuracy 77.1%, Loss: 0.91122, Test Losss: 0.01429\n",
            "Testing: Accuracy: 46.3%, Avg loss: 0.034512 \n",
            "\n",
            "Epoch30:\n",
            "Training: Accuracy 75.8%, Loss: 0.87846, Test Losss: 0.01378\n",
            "Testing: Accuracy: 47.2%, Avg loss: 0.033218 \n",
            "\n",
            "Epoch31:\n",
            "Training: Accuracy 79.0%, Loss: 0.85833, Test Losss: 0.01346\n",
            "Testing: Accuracy: 45.4%, Avg loss: 0.034101 \n",
            "\n",
            "Epoch32:\n",
            "Training: Accuracy 78.2%, Loss: 0.81785, Test Losss: 0.01283\n",
            "Testing: Accuracy: 44.8%, Avg loss: 0.034384 \n",
            "\n",
            "Epoch33:\n",
            "Training: Accuracy 81.1%, Loss: 0.73896, Test Losss: 0.01159\n",
            "Testing: Accuracy: 47.4%, Avg loss: 0.033265 \n",
            "\n",
            "Epoch34:\n",
            "Training: Accuracy 82.3%, Loss: 0.71914, Test Losss: 0.01128\n",
            "Testing: Accuracy: 46.9%, Avg loss: 0.033012 \n",
            "\n",
            "Epoch35:\n",
            "Training: Accuracy 83.3%, Loss: 0.68802, Test Losss: 0.01079\n",
            "Testing: Accuracy: 46.1%, Avg loss: 0.033062 \n",
            "\n",
            "Epoch36:\n",
            "Training: Accuracy 83.3%, Loss: 0.65779, Test Losss: 0.01032\n",
            "Testing: Accuracy: 46.7%, Avg loss: 0.033454 \n",
            "\n",
            "Epoch37:\n",
            "Training: Accuracy 83.7%, Loss: 0.60647, Test Losss: 0.00951\n",
            "Testing: Accuracy: 46.6%, Avg loss: 0.034102 \n",
            "\n",
            "Epoch38:\n",
            "Training: Accuracy 85.4%, Loss: 0.58363, Test Losss: 0.00916\n",
            "Testing: Accuracy: 47.5%, Avg loss: 0.032763 \n",
            "\n",
            "Epoch39:\n",
            "Training: Accuracy 89.5%, Loss: 0.49010, Test Losss: 0.00769\n",
            "Testing: Accuracy: 47.5%, Avg loss: 0.032540 \n",
            "\n",
            "Epoch40:\n",
            "Training: Accuracy 86.8%, Loss: 0.52075, Test Losss: 0.00817\n",
            "Testing: Accuracy: 47.1%, Avg loss: 0.032932 \n",
            "\n",
            "Epoch41:\n",
            "Training: Accuracy 87.6%, Loss: 0.48665, Test Losss: 0.00763\n",
            "Testing: Accuracy: 46.3%, Avg loss: 0.033360 \n",
            "\n",
            "Epoch42:\n",
            "Training: Accuracy 87.6%, Loss: 0.48845, Test Losss: 0.00766\n",
            "Testing: Accuracy: 47.7%, Avg loss: 0.032463 \n",
            "\n",
            "Epoch43:\n",
            "Training: Accuracy 88.7%, Loss: 0.47672, Test Losss: 0.00748\n",
            "Testing: Accuracy: 48.5%, Avg loss: 0.032509 \n",
            "\n",
            "Epoch44:\n",
            "Training: Accuracy 90.8%, Loss: 0.42023, Test Losss: 0.00659\n",
            "Testing: Accuracy: 48.5%, Avg loss: 0.032607 \n",
            "\n",
            "Epoch45:\n",
            "Training: Accuracy 90.2%, Loss: 0.40286, Test Losss: 0.00632\n",
            "Testing: Accuracy: 48.6%, Avg loss: 0.032791 \n",
            "\n",
            "Epoch46:\n",
            "Training: Accuracy 90.9%, Loss: 0.40797, Test Losss: 0.00640\n",
            "Testing: Accuracy: 47.7%, Avg loss: 0.033163 \n",
            "\n",
            "Epoch47:\n",
            "Training: Accuracy 90.5%, Loss: 0.38411, Test Losss: 0.00603\n",
            "Testing: Accuracy: 47.8%, Avg loss: 0.033173 \n",
            "\n",
            "Epoch48:\n",
            "Training: Accuracy 91.5%, Loss: 0.35734, Test Losss: 0.00561\n",
            "Testing: Accuracy: 48.5%, Avg loss: 0.032915 \n",
            "\n",
            "Epoch49:\n",
            "Training: Accuracy 91.7%, Loss: 0.35520, Test Losss: 0.00557\n",
            "Testing: Accuracy: 48.8%, Avg loss: 0.032494 \n",
            "\n",
            "Epoch50:\n",
            "Training: Accuracy 92.5%, Loss: 0.33043, Test Losss: 0.00518\n",
            "Testing: Accuracy: 49.3%, Avg loss: 0.032414 \n",
            "\n",
            "Epoch51:\n",
            "Training: Accuracy 92.5%, Loss: 0.32836, Test Losss: 0.00515\n",
            "Testing: Accuracy: 47.5%, Avg loss: 0.032772 \n",
            "\n",
            "Epoch52:\n",
            "Training: Accuracy 92.9%, Loss: 0.31249, Test Losss: 0.00490\n",
            "Testing: Accuracy: 49.0%, Avg loss: 0.032686 \n",
            "\n",
            "Epoch53:\n",
            "Training: Accuracy 93.5%, Loss: 0.29485, Test Losss: 0.00463\n",
            "Testing: Accuracy: 48.7%, Avg loss: 0.032870 \n",
            "\n",
            "Epoch54:\n",
            "Training: Accuracy 93.8%, Loss: 0.29580, Test Losss: 0.00464\n",
            "Testing: Accuracy: 50.2%, Avg loss: 0.032537 \n",
            "\n",
            "Epoch55:\n",
            "Training: Accuracy 94.9%, Loss: 0.24373, Test Losss: 0.00382\n",
            "Testing: Accuracy: 50.4%, Avg loss: 0.032563 \n",
            "\n",
            "Epoch56:\n",
            "Training: Accuracy 94.8%, Loss: 0.23562, Test Losss: 0.00370\n",
            "Testing: Accuracy: 49.5%, Avg loss: 0.032395 \n",
            "\n",
            "Epoch57:\n",
            "Training: Accuracy 94.1%, Loss: 0.27441, Test Losss: 0.00430\n",
            "Testing: Accuracy: 48.7%, Avg loss: 0.033664 \n",
            "\n",
            "Epoch58:\n",
            "Training: Accuracy 95.1%, Loss: 0.24805, Test Losss: 0.00389\n",
            "Testing: Accuracy: 49.1%, Avg loss: 0.032906 \n",
            "\n",
            "Epoch59:\n",
            "Training: Accuracy 93.7%, Loss: 0.24624, Test Losss: 0.00386\n",
            "Testing: Accuracy: 50.4%, Avg loss: 0.032727 \n",
            "\n",
            "Epoch60:\n",
            "Training: Accuracy 95.5%, Loss: 0.22913, Test Losss: 0.00359\n",
            "Testing: Accuracy: 51.0%, Avg loss: 0.032669 \n",
            "\n",
            "Epoch61:\n",
            "Training: Accuracy 95.8%, Loss: 0.20070, Test Losss: 0.00315\n",
            "Testing: Accuracy: 51.3%, Avg loss: 0.032425 \n",
            "\n",
            "Epoch62:\n",
            "Training: Accuracy 95.8%, Loss: 0.20883, Test Losss: 0.00328\n",
            "Testing: Accuracy: 49.5%, Avg loss: 0.032939 \n",
            "\n",
            "Epoch63:\n",
            "Training: Accuracy 96.0%, Loss: 0.20553, Test Losss: 0.00322\n",
            "Testing: Accuracy: 50.1%, Avg loss: 0.033141 \n",
            "\n",
            "Epoch64:\n",
            "Training: Accuracy 95.1%, Loss: 0.21958, Test Losss: 0.00344\n",
            "Testing: Accuracy: 50.2%, Avg loss: 0.033050 \n",
            "\n",
            "Epoch65:\n",
            "Training: Accuracy 97.1%, Loss: 0.17532, Test Losss: 0.00275\n",
            "Testing: Accuracy: 49.4%, Avg loss: 0.032015 \n",
            "\n",
            "Epoch66:\n",
            "Training: Accuracy 96.6%, Loss: 0.18982, Test Losss: 0.00298\n",
            "Testing: Accuracy: 51.2%, Avg loss: 0.032864 \n",
            "\n",
            "Epoch67:\n",
            "Training: Accuracy 96.9%, Loss: 0.17794, Test Losss: 0.00279\n",
            "Testing: Accuracy: 50.8%, Avg loss: 0.032401 \n",
            "\n",
            "Epoch68:\n",
            "Training: Accuracy 95.4%, Loss: 0.18828, Test Losss: 0.00295\n",
            "Testing: Accuracy: 50.0%, Avg loss: 0.032854 \n",
            "\n",
            "Epoch69:\n",
            "Training: Accuracy 96.8%, Loss: 0.16850, Test Losss: 0.00264\n",
            "Testing: Accuracy: 50.7%, Avg loss: 0.032429 \n",
            "\n",
            "Epoch70:\n",
            "Training: Accuracy 96.0%, Loss: 0.18041, Test Losss: 0.00283\n",
            "Testing: Accuracy: 49.7%, Avg loss: 0.033653 \n",
            "\n",
            "Epoch71:\n",
            "Training: Accuracy 96.6%, Loss: 0.15344, Test Losss: 0.00241\n",
            "Testing: Accuracy: 51.1%, Avg loss: 0.032269 \n",
            "\n",
            "Epoch72:\n",
            "Training: Accuracy 96.6%, Loss: 0.16612, Test Losss: 0.00261\n",
            "Testing: Accuracy: 50.0%, Avg loss: 0.033709 \n",
            "\n",
            "Epoch73:\n",
            "Training: Accuracy 97.2%, Loss: 0.14577, Test Losss: 0.00229\n",
            "Testing: Accuracy: 49.5%, Avg loss: 0.034081 \n",
            "\n",
            "Epoch74:\n",
            "Training: Accuracy 97.1%, Loss: 0.15016, Test Losss: 0.00236\n",
            "Testing: Accuracy: 49.6%, Avg loss: 0.034049 \n",
            "\n",
            "Epoch75:\n",
            "Training: Accuracy 97.0%, Loss: 0.15283, Test Losss: 0.00240\n",
            "Testing: Accuracy: 50.2%, Avg loss: 0.033814 \n",
            "\n",
            "Epoch76:\n",
            "Training: Accuracy 96.8%, Loss: 0.14811, Test Losss: 0.00232\n",
            "Testing: Accuracy: 49.5%, Avg loss: 0.033669 \n",
            "\n",
            "Epoch77:\n",
            "Training: Accuracy 97.4%, Loss: 0.14607, Test Losss: 0.00229\n",
            "Testing: Accuracy: 49.7%, Avg loss: 0.033793 \n",
            "\n",
            "Epoch78:\n",
            "Training: Accuracy 98.2%, Loss: 0.13102, Test Losss: 0.00206\n",
            "Testing: Accuracy: 50.0%, Avg loss: 0.033486 \n",
            "\n",
            "Epoch79:\n",
            "Training: Accuracy 97.5%, Loss: 0.13023, Test Losss: 0.00204\n",
            "Testing: Accuracy: 52.1%, Avg loss: 0.032694 \n",
            "\n",
            "Epoch80:\n",
            "Training: Accuracy 97.6%, Loss: 0.11685, Test Losss: 0.00183\n",
            "Testing: Accuracy: 49.9%, Avg loss: 0.033948 \n",
            "\n",
            "Epoch81:\n",
            "Training: Accuracy 97.7%, Loss: 0.11234, Test Losss: 0.00176\n",
            "Testing: Accuracy: 50.8%, Avg loss: 0.032845 \n",
            "\n",
            "Epoch82:\n",
            "Training: Accuracy 98.0%, Loss: 0.10748, Test Losss: 0.00169\n",
            "Testing: Accuracy: 49.6%, Avg loss: 0.033932 \n",
            "\n",
            "Epoch83:\n",
            "Training: Accuracy 97.3%, Loss: 0.12049, Test Losss: 0.00189\n",
            "Testing: Accuracy: 50.6%, Avg loss: 0.033217 \n",
            "\n",
            "Epoch84:\n",
            "Training: Accuracy 97.9%, Loss: 0.11840, Test Losss: 0.00186\n",
            "Testing: Accuracy: 50.5%, Avg loss: 0.032392 \n",
            "\n",
            "Epoch85:\n",
            "Training: Accuracy 98.2%, Loss: 0.11521, Test Losss: 0.00181\n",
            "Testing: Accuracy: 52.0%, Avg loss: 0.031791 \n",
            "\n",
            "Epoch86:\n",
            "Training: Accuracy 98.5%, Loss: 0.09785, Test Losss: 0.00153\n",
            "Testing: Accuracy: 50.9%, Avg loss: 0.033011 \n",
            "\n",
            "Epoch87:\n",
            "Training: Accuracy 98.6%, Loss: 0.09252, Test Losss: 0.00145\n",
            "Testing: Accuracy: 50.6%, Avg loss: 0.034003 \n",
            "\n",
            "Epoch88:\n",
            "Training: Accuracy 98.7%, Loss: 0.08703, Test Losss: 0.00137\n",
            "Testing: Accuracy: 52.0%, Avg loss: 0.032947 \n",
            "\n",
            "Epoch89:\n",
            "Training: Accuracy 98.7%, Loss: 0.09231, Test Losss: 0.00145\n",
            "Testing: Accuracy: 50.1%, Avg loss: 0.033093 \n",
            "\n",
            "Epoch90:\n",
            "Training: Accuracy 97.9%, Loss: 0.10185, Test Losss: 0.00160\n",
            "Testing: Accuracy: 51.3%, Avg loss: 0.033533 \n",
            "\n",
            "Epoch91:\n",
            "Training: Accuracy 98.5%, Loss: 0.09973, Test Losss: 0.00156\n",
            "Testing: Accuracy: 51.7%, Avg loss: 0.033845 \n",
            "\n",
            "Epoch92:\n",
            "Training: Accuracy 97.4%, Loss: 0.12015, Test Losss: 0.00188\n",
            "Testing: Accuracy: 48.9%, Avg loss: 0.034225 \n",
            "\n",
            "Epoch93:\n",
            "Training: Accuracy 98.4%, Loss: 0.09921, Test Losss: 0.00156\n",
            "Testing: Accuracy: 51.6%, Avg loss: 0.034141 \n",
            "\n",
            "Epoch94:\n",
            "Training: Accuracy 98.5%, Loss: 0.09408, Test Losss: 0.00148\n",
            "Testing: Accuracy: 51.6%, Avg loss: 0.033213 \n",
            "\n",
            "Epoch95:\n",
            "Training: Accuracy 98.5%, Loss: 0.08703, Test Losss: 0.00137\n",
            "Testing: Accuracy: 51.5%, Avg loss: 0.033961 \n",
            "\n",
            "Epoch96:\n",
            "Training: Accuracy 99.3%, Loss: 0.07583, Test Losss: 0.00119\n",
            "Testing: Accuracy: 49.5%, Avg loss: 0.033579 \n",
            "\n",
            "Epoch97:\n",
            "Training: Accuracy 98.7%, Loss: 0.07685, Test Losss: 0.00121\n",
            "Testing: Accuracy: 51.1%, Avg loss: 0.033836 \n",
            "\n",
            "Epoch98:\n",
            "Training: Accuracy 98.2%, Loss: 0.08695, Test Losss: 0.00136\n",
            "Testing: Accuracy: 51.1%, Avg loss: 0.033960 \n",
            "\n",
            "Epoch99:\n",
            "Training: Accuracy 98.6%, Loss: 0.08402, Test Losss: 0.00132\n",
            "Testing: Accuracy: 50.7%, Avg loss: 0.034120 \n",
            "\n",
            "Epoch100:\n",
            "Training: Accuracy 98.7%, Loss: 0.06808, Test Losss: 0.00107\n",
            "Testing: Accuracy: 51.7%, Avg loss: 0.033345 \n",
            "\n",
            "Best Accuracy: 52.05882352941177. Best Loss: 0.0326941406025606\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\tomha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\Conv_v8.cpp:919.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing: Accuracy: 47.4%, Avg loss: 0.038937 \n",
            "\n",
            "Finished\n"
          ]
        }
      ],
      "source": [
        "learningRate = 0.0001\n",
        "batchSize = 128\n",
        "epochs = 100\n",
        "\n",
        "lossFunction = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learningRate)\n",
        "\n",
        "trainingModel(trainingDataloader, model, lossFunction, optimizer, epochs)\n",
        "testModel(testDataloader, model, lossFunction)\n",
        "print(\"Finished\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Test - Accuracy: 47.2%, Avg Loss: 0.038937"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-NN5lbFJbrK"
      },
      "source": [
        "# Saving the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "z6w9-UT1JYgG"
      },
      "outputs": [],
      "source": [
        "model = models.vgg16(weights='IMAGENET1K_V1')\n",
        "torch.save(model, 'model.pth')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ed-V6vOoJtPw"
      },
      "source": [
        "# Loading the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "RUwsJFciJrm_"
      },
      "outputs": [],
      "source": [
        "# model = models.vgg16()\n",
        "# model.load_state_dict(torch.load('model.pth'))\n",
        "# model.eval()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyP5pQ4pqThi+Psu2q1m/Fu+",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
